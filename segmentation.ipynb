{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Atoll Data"
      ],
      "metadata": {
        "id": "jrwndckG6ekg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfF0EJmMSJYC"
      },
      "outputs": [],
      "source": [
        "# Pre-trained Model\n",
        "!pip install git+https://github.com/karolzak/keras-unet\n",
        "\n",
        "# Add other pip installs\n",
        "\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import imageio as iio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAjJr5KCMt4T"
      },
      "outputs": [],
      "source": [
        "# Constants to load data into the model\n",
        "SIZE_X = 256 \n",
        "SIZE_Y = 256\n",
        "n_classes=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToXHgSW5P3i6"
      },
      "outputs": [],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzSnbFmmP0MD"
      },
      "outputs": [],
      "source": [
        "# Rotating all the Images\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image \n",
        "import PIL \n",
        " \n",
        "\n",
        "# assign directory\n",
        "# Note: create a JP_CV_Notebooks shortcut to \"My Drive\" before running\n",
        "GDRIVE_IMGDIR = os.getenv('GDRIVE_IMG')\n",
        "GDRIVE_MASKDIR = os.getenv('GDRIVE_MASK')\n",
        "\n",
        "ImageDirectory = GDRIVE_IMGDIR\n",
        "MaskDirectory = GDRIVE_MASKDIR\n",
        "\n",
        "train_images = []\n",
        "train_masks = [] \n",
        "# iterate over files \n",
        "plt.figure(figsize=(12, 8))\n",
        "   \n",
        "\n",
        "for images in os.listdir(ImageDirectory):\n",
        "    for masks in os.listdir(MaskDirectory):\n",
        "        f = os.path.join(ImageDirectory, images)\n",
        "        b = os.path.join(MaskDirectory, masks)\n",
        "        \n",
        "        if(images == masks):\n",
        "         \n",
        "            img = cv2.imread(f, 0)    \n",
        "            #img = iio.imread(f)  \n",
        "            img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "            train_images.append(img)\n",
        "\n",
        "            hi = cv2.imread(b)       \n",
        "            #mask = iio.imread(b)\n",
        "            mask = hi[:,:,2]\n",
        "            mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST) \n",
        "            train_masks.append(mask)\n",
        "           # print(images + \"=\" + masks)\n",
        "\n",
        "           # plt.subplot(231)\n",
        "           # plt.title(images)\n",
        "           # plt.imshow(img)\n",
        "           # plt.subplot(232)\n",
        "            #plt.title(masks)\n",
        "           # plt.imshow(mask)\n",
        "            #plt.show()\n",
        "\n",
        "            \n",
        "            break\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_masks = np.array(train_masks) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BI7V0vwtMWat"
      },
      "outputs": [],
      "source": [
        "#Image Processing\n",
        "\n",
        "plt.imshow(train_masks[3])\n",
        "plt.show()\n",
        "train_masks[train_masks == 0] = 51 #Replacing 0 class to 51\n",
        "plt.imshow(train_masks[3])\n",
        "plt.show()\n",
        "\n",
        "print(np.unique(train_masks)) # There should be 3 classes printed. If there is four, manually replace the 4th class. \n",
        "print(train_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j9IkkiCAphl"
      },
      "outputs": [],
      "source": [
        "#Run to check if all images match with masks. Don't need to call every time.\n",
        "\n",
        "for n in range(316):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(231)\n",
        "    plt.title('Testing Image' + str(n))\n",
        "    plt.imshow(train_images[n])\n",
        "    plt.subplot(232)\n",
        "    plt.title('Testing Label')\n",
        "    plt.imshow(train_masks[n])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWr8ieOsUisN"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8hbPyIZUhOT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "n, h, w = train_masks.shape\n",
        "train_masks_reshaped = train_masks.reshape(-1,1)\n",
        "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
        "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
        "\n",
        "np.unique(train_masks_encoded_original_shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipY4OV4cUnlP"
      },
      "outputs": [],
      "source": [
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "train_images = normalize(train_images, axis=1)\n",
        "\n",
        "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3Ayl1LaUrQD"
      },
      "source": [
        "### Data Splitting into Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9igYZT3uUvAy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
        "\n",
        "#Further split training data t a smaller subset for quick testing of models\n",
        "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled \n",
        "\n",
        "from keras.utils import to_categorical\n",
        "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
        "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
        "\n",
        "\n",
        "\n",
        "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
        "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5M86wc5U2cz"
      },
      "outputs": [],
      "source": [
        "np.reshape(X_test, (32, 256, 256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnUwTDGMM05u"
      },
      "source": [
        "### Calculate Class Weights(if relevant):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL1l0ylJM894"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(class_weight = \"balanced\",\n",
        "                                                 classes = np.unique(train_masks_reshaped_encoded),\n",
        "                                                 y = train_masks_reshaped_encoded)\n",
        "print(\"Class weights are...:\", class_weights)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "class_weighting = {i : class_weights[i] for i in range(3)}\n",
        "print(class_weight_dict)\n",
        "print(class_weighting)\n",
        "\n",
        "class_weights = np.zeros((227,256,256))\n",
        "class_weights[:, 0] += 0.4368813386093144 # Change value if what is printed by class_weighting is different\n",
        "class_weights[:, 1] += 4.84032092458291 #  Change value if what is printed by class_weighting is different\n",
        "class_weights[:, 2] += 1.9823527953404594 # Change value if what is printed by class_weighting is different\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jo9zqabIMkY"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtGwCSxpRFDz"
      },
      "source": [
        "### Model 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky2uwTunSC85"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "\n",
        "def multi_unet_model(n_classes=3, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "    # Building the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = inputs\n",
        "\n",
        "    # Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    \n",
        "    # Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "     \n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "     \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsB3nXKBRBSf"
      },
      "source": [
        "### Model 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLZ4wR35Q-91"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "\n",
        "\n",
        "################################################################\n",
        "def bn_conv_relu(input, filters, bachnorm_momentum, **conv2d_args):\n",
        "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
        "    x = Conv2D(filters, **conv2d_args)(x)\n",
        "    return x\n",
        "\n",
        "def bn_upconv_relu(input, filters, bachnorm_momentum, **conv2d_trans_args):\n",
        "    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n",
        "    x = Conv2DTranspose(filters, **conv2d_trans_args)(x)\n",
        "    return x\n",
        "\n",
        "def satellite_unet(\n",
        "    input_shape,\n",
        "    num_classes=3,\n",
        "    output_activation='sigmoid',\n",
        "    num_layers=1):\n",
        "\n",
        "    inputs = Input(input_shape)   \n",
        "    \n",
        "    filters = 64\n",
        "    upconv_filters = 96\n",
        "\n",
        "    kernel_size = (3,3)\n",
        "    activation = 'relu'\n",
        "    strides = (1,1)\n",
        "    padding = 'same'\n",
        "    kernel_initializer = 'he_normal'\n",
        "\n",
        "    conv2d_args = {\n",
        "        'kernel_size':kernel_size,\n",
        "        'activation':activation, \n",
        "        'strides':strides,\n",
        "        'padding':padding,\n",
        "        'kernel_initializer':kernel_initializer\n",
        "        }\n",
        "\n",
        "    conv2d_trans_args = {\n",
        "        'kernel_size':kernel_size,\n",
        "        'activation':activation, \n",
        "        'strides':(2,2),\n",
        "        'padding':padding,\n",
        "        'output_padding':(1,1)\n",
        "        }\n",
        "\n",
        "    bachnorm_momentum = 0.01\n",
        "\n",
        "    pool_size = (2,2)\n",
        "    pool_strides = (2,2)\n",
        "    pool_padding = 'valid'\n",
        "\n",
        "    maxpool2d_args = {\n",
        "        'pool_size':pool_size,\n",
        "        'strides':pool_strides,\n",
        "        'padding':pool_padding,\n",
        "        }\n",
        "    \n",
        "    x = Conv2D(filters, **conv2d_args)(inputs)\n",
        "    c1 = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)    \n",
        "    x = bn_conv_relu(c1, filters, bachnorm_momentum, **conv2d_args)\n",
        "    x = MaxPooling2D(**maxpool2d_args)(x)\n",
        "\n",
        "    down_layers = []\n",
        "\n",
        "    for l in range(num_layers):\n",
        "        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "        down_layers.append(x)\n",
        "        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "        x = MaxPooling2D(**maxpool2d_args)(x)\n",
        "\n",
        "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "    x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n",
        "\n",
        "    for conv in reversed(down_layers):        \n",
        "        x = concatenate([x, conv])  \n",
        "        x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n",
        "        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "        x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n",
        "\n",
        "    x = concatenate([x, c1])\n",
        "    x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n",
        "    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n",
        "           \n",
        "    outputs = Conv2D(num_classes, kernel_size=(1,1), strides=(1,1), activation=output_activation, padding='valid') (x)       \n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMrwXeqnM9ow"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEz80ztKSE_1"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_model():\n",
        "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS) #For MOdel 1\n",
        "  #  return satellite_unet(input_shape=(256,256,1)) #For Model 2\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam', loss= tf.keras.losses.BinaryFocalCrossentropy(gamma=2), metrics=['acc'])\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'], sample_weight_mode='temporal') #Uncomment this if using class weights\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNEpPBvgVO2y"
      },
      "source": [
        "### Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHBPetk5VPpj"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train_cat, \n",
        "                    batch_size = 8, \n",
        "                    verbose=1, \n",
        "                    epochs=50, \n",
        "                    validation_data=(X_test, y_test_cat), \n",
        "                   # sample_weight=class_weights, #If using class weights, uncomment this\n",
        "                    shuffle=False)\n",
        "                    \n",
        "\n",
        "DRIVE_FILESAVE = os.getenv('DRIVE_FILESAVE')\n",
        "model.save(DRIVE_FILESAVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y92qGLDOVnGm"
      },
      "outputs": [],
      "source": [
        "# # In case you need to load the model\n",
        "from tensorflow import keras\n",
        "MODEL_DIR = os.getenv('MODEL_1')\n",
        "model = keras.models.load_model(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HyOkISaNCQT"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RB0CYAQWA5Y"
      },
      "source": [
        "### Evaluating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un3Mjz66V_yS"
      },
      "outputs": [],
      "source": [
        "_, acc = model.evaluate(X_test, y_test_cat)\n",
        "model.evaluate(X_test, y_test_cat)\n",
        "#model.summary()\n",
        "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrYA4bmqWYXL"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFFsHHQpWXlv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "y_pred=model.predict(X_test)\n",
        "\n",
        "print(y_test_cat.shape)\n",
        "print(y_pred.shape)\n",
        "\n",
        "#IMPORTANT STEP: if anything about the image size or number of images is changed, make sure to change reshaped value.\n",
        "#Should go from: (Number of images, SIZE_X, SIZE_Y, 3) to (Number of images * SIZE_X * SIZE_Y, 3)\n",
        "Y_testing = np.reshape(y_test_cat, (2097152, 3))\n",
        "Y_predict = np.reshape(y_pred, (2097152, 3))\n",
        "\n",
        "print(Y_testing.shape)\n",
        "print(Y_predict.shape)\n",
        "\n",
        "Y_predict=np.argmax(Y_predict, axis=1)\n",
        "Y_testing=np.argmax(Y_testing, axis=1)\n",
        "\n",
        "print(Y_testing.shape)\n",
        "print(Y_predict.shape)\n",
        "\n",
        "\n",
        "result =confusion_matrix(Y_testing, Y_predict)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=result)\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqq73bGSWeCO"
      },
      "source": [
        "### Mean IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY7zjxDfWfJC"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
        "\n",
        "# Using built in keras function\n",
        "from keras.metrics import MeanIoU\n",
        "n_classes = 3\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
        "\n",
        "\n",
        "# To calculate I0U for each class...\n",
        "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
        "print(values)\n",
        "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[1,0]+ values[2,0])\n",
        "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[0,1]+ values[2,1])\n",
        "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[0,2]+ values[1,2])\n",
        "# class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
        "\n",
        "print(\"IoU for class1 is: \", class1_IoU)\n",
        "print(\"IoU for class2 is: \", class2_IoU)\n",
        "print(\"IoU for class3 is: \", class3_IoU)\n",
        "# print(\"IoU for class4 is: \", class4_IoU)\n",
        "\n",
        "plt.imshow(train_images[2, :,:,0], cmap='gray')\n",
        "plt.imshow(train_masks[2], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQCWx1kpWuj_"
      },
      "source": [
        "### Comparing Ground Truth to Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2W74nvrXCBJ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "for x in range(len(X_test)):\n",
        "    test_img = X_test[x]\n",
        "    ground_truth=y_test[x]\n",
        "    test_img_norm=test_img[:,:,0][:,:,None]\n",
        "    test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "    prediction = (model.predict(test_img_input))\n",
        "    predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(231)\n",
        "    plt.title('Testing Image')\n",
        "    plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "    plt.subplot(232)\n",
        "    plt.title('Testing Label')\n",
        "    plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
        "    plt.subplot(233)\n",
        "    plt.title('Prediction on test image')\n",
        "    plt.imshow(predicted_img, cmap='jet')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ef1rAjeIMrb"
      },
      "source": [
        "## Experimentation\n",
        "\n",
        "**Table for Model 1**\n",
        "\n",
        "BFC = BinaryFocalCrossentropy\n",
        "\n",
        "| Model | Epochs| Batchsize|Loss Function|Class_Weight|Accuracy|Mean IOU|\n",
        "|:------|-------|----------|-------------|------------|--------|--------|\n",
        "|1_model| 30    |  8       |  BFC        |  No        |  79    |   0.26 |\n",
        "|2_model|100    |  8       |  BFC        | Yes        |83.9    |   0.42 |\n",
        "|3_model|200    |  8       |  BFC        | Yes        | 85     |   0.56 |\n",
        "|4_model| 50    |  16      |  BFC        |  Yes       | 79     | 0.36   |\n",
        "|5_model| 200   |  8       |  BFC        |   No       |88.9    |   0.61 |\n",
        "|6_model| 30    |  8       |  BFC        | Yes        | 80     |  0.35  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlVTsRG7P4o8"
      },
      "source": [
        "## Observations from the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gvFWPBZZGCb"
      },
      "source": [
        "### Interrater Agreement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9sq2-VBRuAF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRpBgKiWZIy_"
      },
      "outputs": [],
      "source": [
        "def image_to_a_numpy_array(fname):\n",
        "\n",
        "  img = np.array(Image.open(fname))\n",
        "\n",
        "  height, width, num_bands = img.shape\n",
        "\n",
        "  print('Image Size: ', img.shape)\n",
        "\n",
        "  res = img.reshape(-1, num_bands)\n",
        "\n",
        "  res = res.astype('float64')\n",
        "\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__46VDsFZK4C"
      },
      "outputs": [],
      "source": [
        "def calculate_and_plot_cohen_kappa(file_name, folder_paths):\n",
        "\n",
        "  img_1_path = folder_paths[0] + file_name\n",
        "  img_2_path = folder_paths[1] + file_name\n",
        "  img_3_path = folder_paths[2] + file_name\n",
        "\n",
        "  img_1 = image_to_a_numpy_array(img_1_path)\n",
        "  img_2 = image_to_a_numpy_array(img_2_path)\n",
        "  img_3 = image_to_a_numpy_array(img_3_path)\n",
        "\n",
        "  imgs = [img_1, img_2, img_3]\n",
        "\n",
        "  ck_12 = cohen_kappa_score(img_1.flatten(), img_2.flatten())\n",
        "  ck_13 = cohen_kappa_score(img_1.flatten(), img_3.flatten())\n",
        "  ck_23 = cohen_kappa_score(img_2.flatten(), img_3.flatten())\n",
        "\n",
        "  print('------------------------------------------------------')\n",
        "  print(f'Printing Cohen Kappa Scores for image {file_name}')\n",
        "  print('------------------------------------------------------')\n",
        "  print('Cohen Kappa Score of Labeler 1 and Labeler 2: ', ck_12)\n",
        "  print('------------------------------------------------------')\n",
        "  print('Cohen Kappa Score of Labeler 1 and Labeler 3: ', ck_13)\n",
        "  print('------------------------------------------------------')\n",
        "  print('Cohen Kappa Score of Labeler 2 and Labeler 3: ', ck_23)\n",
        "  print('------------------------------------------------------\\n')\n",
        "  print('Plotting Graphs...\\n')\n",
        "  plt.figure(figsize=(10, 10))\n",
        "\n",
        "  plt.subplot(211)\n",
        "\n",
        "  bar_chart = plt.bar(['L_1 - L_2', 'L_1 - L_3', 'L_2 - L_3'], \n",
        "                    [ck_12, ck_13, ck_23], align='center')\n",
        "\n",
        "  plt.ylim(0, 1)  \n",
        "  plt.title(f'Cohen Kappa Score for {file_name}')\n",
        "  plt.xlabel('Pairs of Labelers')\n",
        "  plt.ylabel('Cohen Kappa Score')\n",
        "\n",
        "  plt.subplot(212)\n",
        "\n",
        "  data = {'Labeler 1': [ck_12, ck_13],\n",
        "        'Labeler 2': [ck_12, ck_23],\n",
        "        'Labeler 3': [ck_13, ck_23]}\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  heatmap = sns.heatmap(df, annot=True, cmap='coolwarm')\n",
        "  plt.xlabel('Labelers')\n",
        "  plt.ylabel('Other Labelers')\n",
        "\n",
        "  return [ck_12, ck_13, ck_23]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4T1HNnfZVio"
      },
      "outputs": [],
      "source": [
        "AGREEMENT = os.getenv('AGREEMENT_FILEPATH')\n",
        "folder_path = AGREEMENT\n",
        "folder_paths = [folder_path+os.getenv('NAME_1'), folder_path+os.getenv('NAME_2'), folder_path+os.getenv('NAME_3')]\n",
        "\n",
        "img_names = ['1.png', '2.png']\n",
        "\n",
        "length_of_test_dataset = len(img_names)\n",
        "\n",
        "results = []\n",
        "\n",
        "for img_name in img_names:\n",
        "\n",
        "  res = calculate_and_plot_cohen_kappa(img_name, folder_paths)\n",
        "\n",
        "  results.append(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHoPAzVcZkkH"
      },
      "outputs": [],
      "source": [
        "ck_12_average_score = 0\n",
        "ck_13_average_score = 0\n",
        "ck_23_average_score = 0\n",
        "\n",
        "for i in range(len(img_names)):\n",
        "\n",
        "  ck_12_average_score += results[i][0]/length_of_test_dataset\n",
        "  ck_13_average_score += results[i][1]/length_of_test_dataset\n",
        "  ck_23_average_score += results[i][2]/length_of_test_dataset\n",
        "\n",
        "print('------------------------------------------------------')\n",
        "print('Printing Average Cohen Kappa Scores')\n",
        "print('------------------------------------------------------')\n",
        "print('Average Cohen Kappa Score of Labeler 1 and Labeler 2: ', ck_12_average_score)\n",
        "print('------------------------------------------------------')\n",
        "print('Average Cohen Kappa Score of Labeler 1 and Labeler 3: ', ck_13_average_score)\n",
        "print('------------------------------------------------------')\n",
        "print('Average Cohen Kappa Score of Labeler 2 and Labeler 3: ', ck_23_average_score)\n",
        "print('------------------------------------------------------\\n')\n",
        "print('Plotting Graphs...\\n')\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(211)\n",
        "\n",
        "bar_chart = plt.bar(['L_1 - L_2', 'L_1 - L_3', 'L_2 - L_3'], \n",
        "                    [ck_12_average_score, ck_13_average_score, ck_23_average_score], align='center')\n",
        "\n",
        "plt.ylim(0, 1)  \n",
        "plt.title('Average Cohen Kappa Coefficient')\n",
        "plt.xlabel('Pairs of Labelers')\n",
        "plt.ylabel('Cohen Kappa Coefficient')\n",
        "plt.savefig('Cohen Kappa Score.png')\n",
        "\n",
        "plt.subplot(212)\n",
        "\n",
        "data = {'Labeler 1': [ck_12_average_score, ck_13_average_score],\n",
        "        'Labeler 2': [ck_12_average_score, ck_23_average_score],\n",
        "        'Labeler 3': [ck_13_average_score, ck_23_average_score]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "heatmap = sns.heatmap(df, annot=True, cmap='coolwarm')\n",
        "plt.xlabel('Labelers')\n",
        "plt.ylabel('Other Labelers')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TES8ZmsKP-ci"
      },
      "source": [
        "## Future work plan for improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNcjFOCPZ1yP"
      },
      "source": [
        "* Train on more data: more annotation with Dash Doodler\n",
        "* Different approach to annotation: use Kmeans images as masks for annotation instead of dash doodler since dash doodler susceptible to human error. One caveat: classes are consistently labeled with Kmeans\n",
        "* Different models: We use UNet here, but there are other segmentation models online that could be used\n",
        "* More hyperparameter tuning could be done. Most of the tuning was not documented since results all ended up looking/averaging the same.\n",
        "* Create a more streamlined way of data manipulation. Currently, going from Dash_Doodler to feeding the model takes far too many steps in manipulation: Much of it isn't documented here because its all grunt work that can be easily resolved by a python script. If interested in the process and script, refer to Miscellaneous.ipynb in folder."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}